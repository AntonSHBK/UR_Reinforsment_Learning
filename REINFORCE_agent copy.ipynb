{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE Agent\n",
    "\n",
    "## Setup step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%udo` not found.\n"
     ]
    }
   ],
   "source": [
    "%udo apt-get update\n",
    "%pip install scipy\n",
    "%pip install tensorflow\n",
    "%pip install tf-agents\n",
    "%pip install dm-reverb[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_agents\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# from tf_agents.environments import py_environment\n",
    "# from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "# from tf_agents.policies import py_tf_eager_policy\n",
    "# from tf_agents.drivers import py_driver\n",
    "from tf_agents.agents.reinforce import reinforce_agent\n",
    "from tf_agents.environments import utils\n",
    "# from tf_agents.specs import array_spec\n",
    "# from tf_agents.trajectories import time_step\n",
    "# from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.policies import random_tf_policy\n",
    "# from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "# from tf_agents.replay_buffers import reverb_utils\n",
    "\n",
    "from tf_env.UR_ENV import UR_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iterations = 20 # @param {type:\"integer\"}\n",
    "discount = 0.99 # @param {type:\"number\"}\n",
    "fc_layer_params=(50,50)\n",
    "learning_rate = 1e-3 # @param {type:\"number\"}\n",
    "number_eval_episodes = 3 # @param {type:\"integer\"}\n",
    "collect_episodes_per_iteration = 5 # @param {type:\"integer\"}\n",
    "# collect_max_steps = 20 # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 1000 # @param {type:\"integer\"}\n",
    "log_interval = 10 # @param {type:\"integer\"}\n",
    "eval_interval = 20 # @param {type:\"integer\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Usually we create two environments: one for training and one for evaluation. Most environments are written in pure python, but they can be easily converted to TensorFlow using the TFPyEnvironment wrapper. The original environment's API uses numpy arrays, the TFPyEnvironment converts these to/from Tensors for you to more easily interact with TensorFlow policies and agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env_py= UR_env()\n",
    "eval_env_py=UR_env()\n",
    "\n",
    "train_env_tf=tf_py_environment.TFPyEnvironment(train_env_py)\n",
    "eval_env_tf=tf_py_environment.TFPyEnvironment(eval_env_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(2, 3), dtype=tf.float32, name='observation', minimum=array(-3.4028235e+38, dtype=float32), maximum=array(3.4028235e+38, dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env_tf.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(6,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env_tf.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env_tf.discount_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.float32, name='reward')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env_tf.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': BoundedTensorSpec(shape=(2, 3), dtype=tf.float32, name='observation', minimum=array(-3.4028235e+38, dtype=float32), maximum=array(3.4028235e+38, dtype=float32)),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env_tf.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '<bound method UR_env.batch_size of <tf_env.UR_ENV.UR_env object at 0x000001E3568F6740>>' with type '<class 'method'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_env_tf\u001b[39m.\u001b[39;49mcurrent_time_step()\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tf_agents\\environments\\tf_environment.py:196\u001b[0m, in \u001b[0;36mTFEnvironment.current_time_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcurrent_time_step\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    186\u001b[0m   \u001b[39m\"\"\"Returns the current `TimeStep`.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \n\u001b[0;32m    188\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_current_time_step()\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:242\u001b[0m, in \u001b[0;36mTFPyEnvironment._current_time_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39m'\u001b[39m\u001b[39mcurrent_time_step\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    237\u001b[0m   outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnumpy_function(\n\u001b[0;32m    238\u001b[0m       _isolated_current_time_step_py,\n\u001b[0;32m    239\u001b[0m       [],  \u001b[39m# No inputs.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time_step_dtypes,\n\u001b[0;32m    241\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcurrent_time_step_py_func\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 242\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_time_step_from_numpy_function_outputs(outputs)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tf_agents\\environments\\tf_py_environment.py:375\u001b[0m, in \u001b[0;36mTFPyEnvironment._time_step_from_numpy_function_outputs\u001b[1;34m(self, outputs)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39m\"\"\"Forms a `TimeStep` from the output of the numpy_function outputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m batch_shape \u001b[39m=\u001b[39m () \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatched \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,)\n\u001b[1;32m--> 375\u001b[0m batch_shape \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mTensorShape(batch_shape)\n\u001b[0;32m    376\u001b[0m time_step \u001b[39m=\u001b[39m _pack_named_sequence(outputs,\n\u001b[0;32m    377\u001b[0m                                  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_step_spec(),\n\u001b[0;32m    378\u001b[0m                                  batch_shape)\n\u001b[0;32m    379\u001b[0m \u001b[39mreturn\u001b[39;00m time_step\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:776\u001b[0m, in \u001b[0;36mTensorShape.__init__\u001b[1;34m(self, dims)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39m\"\"\"Creates a new TensorShape with the given dimensions.\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \n\u001b[0;32m    769\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[39m  TypeError: If dims cannot be converted to a list of dimensions.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dims, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):  \u001b[39m# Most common case.\u001b[39;00m\n\u001b[1;32m--> 776\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dims \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(as_dimension(d)\u001b[39m.\u001b[39;49mvalue \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m dims)\n\u001b[0;32m    777\u001b[0m \u001b[39melif\u001b[39;00m dims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dims \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:776\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39m\"\"\"Creates a new TensorShape with the given dimensions.\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \n\u001b[0;32m    769\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[39m  TypeError: If dims cannot be converted to a list of dimensions.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dims, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):  \u001b[39m# Most common case.\u001b[39;00m\n\u001b[1;32m--> 776\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dims \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(as_dimension(d)\u001b[39m.\u001b[39mvalue \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dims)\n\u001b[0;32m    777\u001b[0m \u001b[39melif\u001b[39;00m dims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dims \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:740\u001b[0m, in \u001b[0;36mas_dimension\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    738\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m    739\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m   \u001b[39mreturn\u001b[39;00m Dimension(value)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:216\u001b[0m, in \u001b[0;36mDimension.__init__\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    214\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(value\u001b[39m.\u001b[39m\u001b[39m__index__\u001b[39m())\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 216\u001b[0m   six\u001b[39m.\u001b[39;49mraise_from(\n\u001b[0;32m    217\u001b[0m       \u001b[39mTypeError\u001b[39;49;00m(\u001b[39m\"\u001b[39;49m\u001b[39mDimension value must be integer or None or have \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    218\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39man __index__ method, got value \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{0!r}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m with type \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{1!r}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    219\u001b[0m                 \u001b[39m.\u001b[39;49mformat(value, \u001b[39mtype\u001b[39;49m(value))), \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    221\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDimension \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m must be >= 0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '<bound method UR_env.batch_size of <tf_env.UR_ENV.UR_env object at 0x000001E3568F6740>>' with type '<class 'method'>'"
     ]
    }
   ],
   "source": [
    "train_env_tf.current_time_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_env_tf.batch_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pandas.DataFrame(columns=['step_type', 'reward', 'discount', 'observation'])\n",
    "# t_step = train_env_tf.reset()\n",
    "# df = df.append(\n",
    "#     {\n",
    "#     'step_type': t_step.step_type, \n",
    "#     'reward': t_step.reward, \n",
    "#     'discount': t_step.discount, \n",
    "#     'observation': t_step.observation\n",
    "#     }, \n",
    "#     ignore_index=True\n",
    "# )\n",
    "# while not t_step.is_last():\n",
    "#     action = np.array([[1,1,1,1,1,1]],dtype=np.float32)\n",
    "#     t_step = train_env_tf.step(action)\n",
    "#     df = df.append(\n",
    "#         {\n",
    "#         'step_type': t_step.step_type, \n",
    "#         'reward': t_step.reward, \n",
    "#         'discount': t_step.discount, \n",
    "#         'observation': t_step.observation\n",
    "#         }, \n",
    "#         ignore_index=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "### Actor Network Policies\n",
    "The algorithm that we use to solve an RL problem is represented as an Agent. In addition to the REINFORCE agent, TF-Agents provides standard implementations of a variety of Agents such as DQN, DDPG, TD3, PPO and SAC.\n",
    "\n",
    "To create a REINFORCE Agent, we first need an Actor Network that can learn to predict the action given an observation from the environment.\n",
    "\n",
    "We can easily create an Actor Network using the specs of the observations and actions. We can specify the layers in the network which, in this example, is the fc_layer_params argument set to a tuple of ints representing the sizes of each hidden layer (see the Hyperparameters section above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks import actor_distribution_network\n",
    "\n",
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    train_env_tf.observation_spec(),\n",
    "    train_env_tf.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need an optimizer to train the network we just created, and a train_step_counter variable to keep track of how many times the network was updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_counter = tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_agent = reinforce_agent.ReinforceAgent(\n",
    "    train_env_tf.time_step_spec(),\n",
    "    train_env_tf.action_spec(),\n",
    "    actor_network=actor_net,\n",
    "    optimizer=optimizer,\n",
    "    normalize_returns=True,\n",
    "    train_step_counter=train_step_counter)\n",
    "tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(6,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(2, 3), dtype=tf.float32, name='observation', minimum=array(-3.4028235e+38, dtype=float32), maximum=array(3.4028235e+38, dtype=float32)),\n",
       " 'policy_info': (),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policies\n",
    "In TF-Agents, policies represent the standard notion of policies in RL: given a time_step produce an action or a distribution over actions. The main method is policy_step = policy.action(time_step) where policy_step is a named tuple PolicyStep(action, state, info). The policy_step.action is the action to be applied to the environment, state represents the state for stateful (RNN) policies and info may contain auxiliary information such as log probabilities of the actions.\n",
    "\n",
    "Agents contain two policies: the main policy that is used for evaluation/deployment (agent.policy) and another policy that is used for data collection (agent.collect_policy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = tf_agent.policy\n",
    "collect_policy = tf_agent.collect_policy\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(\n",
    "    time_step_spec=train_env_tf.time_step_spec(),\n",
    "    action_spec=train_env_tf.action_spec()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and Evaluation\n",
    "The most common metric used to evaluate a policy is the average return. The return is the sum of rewards obtained while running a policy in an environment for an episode, and we usually average this over a few episodes. We can compute the average return metric as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer\n",
    "Reinforcement learning algorithms use replay buffers to store trajectories of experience when executing a policy in an environment. During training, replay buffers are queried for a subset of the trajectories (either a sequential subset or a sample) to \"replay\" the agent's experience.\n",
    "\n",
    "In TF-Agents we use a Driver (see the Driver tutorial for more details) to collect experience in an environment. To use a Driver, we specify an Observer that is a function for the Driver to execute when it receives a trajectory.\n",
    "\n",
    "TFUniformReplayBuffer is the most commonly used replay buffer in TF-Agents, thus we will use here. In TFUniformReplayBuffer the backing buffer storage is done by tensorflow variables and thus is part of the compute graph.\n",
    "\n",
    "The buffer stores batches of elements and has a maximum capacity max_length elements per batch segment. Thus, the total buffer capacity is batch_size x max_length elements. The elements stored in the buffer must all have a matching data spec. When the replay buffer is used for data collection, the spec is the agent's collect data spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec = tf_agent.collect_data_spec,\n",
    "    batch_size = train_env_tf.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "    \n",
    "rb_observer = [replay_buffer.add_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(train_env_tf.batch_size)\n",
    "print(train_env_tf.batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As REINFORCE learns from whole episodes, we define a function to collect an episode using the given data collection policy and save the data (observations, actions, rewards etc.) as trajectories in the replay buffer. Here we are using 'PyDriver' to run the experience collecting loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_episode(environment, policy, max_episodes):\n",
    "  collect_op = dynamic_step_driver.DynamicStepDriver(\n",
    "    environment,\n",
    "    tf_agent.collect_policy,\n",
    "    observers=rb_observer,\n",
    "    num_steps=max_episodes).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent\n",
    "The training loop involves both collecting data from the environment and optimizing the agent's networks. Along the way, we will occasionally evaluate the agent's policy to see how we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42416838]\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env_tf, tf_agent.policy, number_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "print(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [95], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_iterations):\n\u001b[0;32m      2\u001b[0m   \u001b[39m# Collect a few episodes using collect_policy and save to the replay buffer.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m   collect_episode(train_env_tf, tf_agent\u001b[39m.\u001b[39mcollect_policy, \u001b[39m2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m   dataset \u001b[39m=\u001b[39m replay_buffer\u001b[39m.\u001b[39;49mas_dataset(sample_batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m   iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(dataset)\n\u001b[0;32m      9\u001b[0m   trajectories, _ \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\gin\\config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tf_agents\\replay_buffers\\tf_uniform_replay_buffer.py:305\u001b[0m, in \u001b[0;36mTFUniformReplayBuffer.as_dataset\u001b[1;34m(self, sample_batch_size, num_steps, num_parallel_calls, single_deterministic_pass)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[39m@gin\u001b[39m\u001b[39m.\u001b[39mconfigurable(\n\u001b[0;32m    299\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtf_agents.tf_uniform_replay_buffer.TFUniformReplayBuffer.as_dataset\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mas_dataset\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m                num_parallel_calls\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    304\u001b[0m                single_deterministic_pass\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 305\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TFUniformReplayBuffer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mas_dataset(\n\u001b[0;32m    306\u001b[0m       sample_batch_size, num_steps, num_parallel_calls,\n\u001b[0;32m    307\u001b[0m       single_deterministic_pass\u001b[39m=\u001b[39;49msingle_deterministic_pass)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tf_agents\\replay_buffers\\replay_buffer.py:228\u001b[0m, in \u001b[0;36mReplayBuffer.as_dataset\u001b[1;34m(self, sample_batch_size, num_steps, num_parallel_calls, sequence_preprocess_fn, single_deterministic_pass)\u001b[0m\n\u001b[0;32m    222\u001b[0m   ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_deterministic_pass_dataset(\n\u001b[0;32m    223\u001b[0m       sample_batch_size\u001b[39m=\u001b[39msample_batch_size,\n\u001b[0;32m    224\u001b[0m       num_steps\u001b[39m=\u001b[39mnum_steps,\n\u001b[0;32m    225\u001b[0m       sequence_preprocess_fn\u001b[39m=\u001b[39msequence_preprocess_fn,\n\u001b[0;32m    226\u001b[0m       num_parallel_calls\u001b[39m=\u001b[39mnum_parallel_calls)\n\u001b[0;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m   ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_as_dataset(\n\u001b[0;32m    229\u001b[0m       sample_batch_size\u001b[39m=\u001b[39;49msample_batch_size,\n\u001b[0;32m    230\u001b[0m       num_steps\u001b[39m=\u001b[39;49mnum_steps,\n\u001b[0;32m    231\u001b[0m       sequence_preprocess_fn\u001b[39m=\u001b[39;49msequence_preprocess_fn,\n\u001b[0;32m    232\u001b[0m       num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls)\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_dataset:\n\u001b[0;32m    235\u001b[0m   options \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mOptions()\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tf_agents\\replay_buffers\\tf_uniform_replay_buffer.py:342\u001b[0m, in \u001b[0;36mTFUniformReplayBuffer._as_dataset\u001b[1;34m(self, sample_batch_size, num_steps, sequence_preprocess_fn, num_parallel_calls)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_next\u001b[39m(_):\n\u001b[0;32m    340\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_next(sample_batch_size, num_steps, time_stacked\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 342\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mexperimental\u001b[39m.\u001b[39;49mCounter()\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    343\u001b[0m     get_next, num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls)\n\u001b[0;32m    344\u001b[0m \u001b[39mreturn\u001b[39;00m dataset\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2202\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2199\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[0;32m   2200\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2201\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2202\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2204\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[0;32m   2205\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[0;32m   2206\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2209\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2210\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5400\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m   5399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[1;32m-> 5400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5401\u001b[0m     map_func,\n\u001b[0;32m   5402\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m   5403\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m   5404\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m   5405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m   5406\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[0;32m   5407\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5411\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m   5412\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    249\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\3EC2~1\\AppData\\Local\\Temp\\__autograph_generated_filec06a2e9f.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_next\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mget_next, (ag__\u001b[39m.\u001b[39;49mld(sample_batch_size), ag__\u001b[39m.\u001b[39;49mld(num_steps)), \u001b[39mdict\u001b[39;49m(time_stacked\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), fscope)\n\u001b[0;32m     17\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\3EC2~1\\AppData\\Local\\Temp\\__autograph_generated_fileymn8lrcs.py:54\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(func), \u001b[39mtuple\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(args)), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(kwargs)), fscope)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32mC:\\Users\\3EC2~1\\AppData\\Local\\Temp\\__autograph_generated_fileyt0t0ymr.py:55\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_next\u001b[1;34m(self, sample_batch_size, num_steps, time_stacked)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_get_next, (ag__\u001b[39m.\u001b[39;49mld(sample_batch_size), ag__\u001b[39m.\u001b[39;49mld(num_steps), ag__\u001b[39m.\u001b[39;49mld(time_stacked)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:427\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m   program_ctx \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39mProgramContext(options\u001b[39m=\u001b[39moptions)\n\u001b[1;32m--> 427\u001b[0m   converted_f \u001b[39m=\u001b[39m _convert_actual(target_entity, program_ctx)\n\u001b[0;32m    428\u001b[0m   \u001b[39mif\u001b[39;00m logging\u001b[39m.\u001b[39mhas_verbosity(\u001b[39m2\u001b[39m):\n\u001b[0;32m    429\u001b[0m     _log_callargs(converted_f, effective_args, kwargs)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:269\u001b[0m, in \u001b[0;36m_convert_actual\u001b[1;34m(entity, program_ctx)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(entity, \u001b[39m'\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    265\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot apply autograph to a function that doesn\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    266\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mexpose a __code__ object. If this is a @tf.function,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    267\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m try passing f.python_function instead.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m transformed, module, source_map \u001b[39m=\u001b[39m _TRANSPILER\u001b[39m.\u001b[39;49mtransform(entity, program_ctx)\n\u001b[0;32m    271\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_module\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    272\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformed, \u001b[39m'\u001b[39m\u001b[39mag_source_map\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:282\u001b[0m, in \u001b[0;36mGenericTranspiler.transform\u001b[1;34m(self, obj, user_context)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39m\"\"\"Transforms a Python object.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \n\u001b[0;32m    269\u001b[0m \u001b[39mUsers typically call this method.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39m  NotImplementedError: if the type of obj is not handled.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misfunction(obj) \u001b[39mor\u001b[39;00m inspect\u001b[39m.\u001b[39mismethod(obj):\n\u001b[1;32m--> 282\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_function(obj, user_context)\n\u001b[0;32m    284\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNon-function: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(obj)))\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:466\u001b[0m, in \u001b[0;36mPyToPy.transform_function\u001b[1;34m(self, fn, user_context)\u001b[0m\n\u001b[0;32m    464\u001b[0m logging\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not cached for subkey \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, fn, cache_subkey)\n\u001b[0;32m    465\u001b[0m \u001b[39m# TODO(mdan): Confusing overloading pattern. Fix.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m nodes, ctx \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(PyToPy, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtransform_function(fn, user_context)\n\u001b[0;32m    468\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(nodes, gast\u001b[39m.\u001b[39mLambda):\n\u001b[0;32m    469\u001b[0m   nodes \u001b[39m=\u001b[39m gast\u001b[39m.\u001b[39mAssign(\n\u001b[0;32m    470\u001b[0m       targets\u001b[39m=\u001b[39m[\n\u001b[0;32m    471\u001b[0m           gast\u001b[39m.\u001b[39mName(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    476\u001b[0m       ],\n\u001b[0;32m    477\u001b[0m       value\u001b[39m=\u001b[39mnodes)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:359\u001b[0m, in \u001b[0;36mGenericTranspiler.transform_function\u001b[1;34m(self, fn, user_context)\u001b[0m\n\u001b[0;32m    356\u001b[0m context \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mContext(entity_info, namer, user_context)\n\u001b[0;32m    358\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_erase_arg_defaults(node)\n\u001b[1;32m--> 359\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_ast(node, context)\n\u001b[0;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m result, context\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:247\u001b[0m, in \u001b[0;36mPyToTF.transform_ast\u001b[1;34m(self, node, ctx)\u001b[0m\n\u001b[0;32m    243\u001b[0m   node \u001b[39m=\u001b[39m asserts\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[0;32m    244\u001b[0m \u001b[39m# Note: sequencing continue canonicalization before for loop one avoids\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m# dealing with the extra loop increment operation that the for\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39m# canonicalization creates.\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m node \u001b[39m=\u001b[39m continue_statements\u001b[39m.\u001b[39;49mtransform(node, ctx)\n\u001b[0;32m    248\u001b[0m node \u001b[39m=\u001b[39m return_statements\u001b[39m.\u001b[39mtransform(node, ctx)\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m ctx\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39muses(converter\u001b[39m.\u001b[39mFeature\u001b[39m.\u001b[39mLISTS):\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:163\u001b[0m, in \u001b[0;36mtransform\u001b[1;34m(node, ctx)\u001b[0m\n\u001b[0;32m    160\u001b[0m node \u001b[39m=\u001b[39m qual_names\u001b[39m.\u001b[39mresolve(node)\n\u001b[0;32m    161\u001b[0m node \u001b[39m=\u001b[39m activity\u001b[39m.\u001b[39mresolve(node, ctx, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 163\u001b[0m node \u001b[39m=\u001b[39m ContinueCanonicalizationTransformer(ctx)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    164\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:486\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m old_value:\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n\u001b[1;32m--> 486\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(value)\n\u001b[0;32m    487\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:143\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer.visit_With\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_With\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m    142\u001b[0m   node\u001b[39m.\u001b[39mitems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_block(node\u001b[39m.\u001b[39mitems)\n\u001b[1;32m--> 143\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visit_non_loop_body(node\u001b[39m.\u001b[39;49mbody)\n\u001b[0;32m    144\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:117\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer._visit_non_loop_body\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_visit_non_loop_body\u001b[39m(\u001b[39mself\u001b[39m, nodes):\n\u001b[0;32m    116\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39menter()\n\u001b[1;32m--> 117\u001b[0m   nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(nodes, after_visit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_postprocess_statement)\n\u001b[0;32m    118\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39mexit()\n\u001b[0;32m    119\u001b[0m   \u001b[39mreturn\u001b[39;00m nodes\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[1;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[0;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m   before_visit()\n\u001b[1;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[0;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:143\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer.visit_With\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_With\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m    142\u001b[0m   node\u001b[39m.\u001b[39mitems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_block(node\u001b[39m.\u001b[39mitems)\n\u001b[1;32m--> 143\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visit_non_loop_body(node\u001b[39m.\u001b[39;49mbody)\n\u001b[0;32m    144\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:117\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer._visit_non_loop_body\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_visit_non_loop_body\u001b[39m(\u001b[39mself\u001b[39m, nodes):\n\u001b[0;32m    116\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39menter()\n\u001b[1;32m--> 117\u001b[0m   nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(nodes, after_visit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_postprocess_statement)\n\u001b[0;32m    118\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39mexit()\n\u001b[0;32m    119\u001b[0m   \u001b[39mreturn\u001b[39;00m nodes\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[1;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[0;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m   before_visit()\n\u001b[1;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[0;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:143\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer.visit_With\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_With\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m    142\u001b[0m   node\u001b[39m.\u001b[39mitems \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_block(node\u001b[39m.\u001b[39mitems)\n\u001b[1;32m--> 143\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visit_non_loop_body(node\u001b[39m.\u001b[39;49mbody)\n\u001b[0;32m    144\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:117\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer._visit_non_loop_body\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_visit_non_loop_body\u001b[39m(\u001b[39mself\u001b[39m, nodes):\n\u001b[0;32m    116\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39menter()\n\u001b[1;32m--> 117\u001b[0m   nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(nodes, after_visit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_postprocess_statement)\n\u001b[0;32m    118\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39mexit()\n\u001b[0;32m    119\u001b[0m   \u001b[39mreturn\u001b[39;00m nodes\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[1;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[0;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m   before_visit()\n\u001b[1;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[0;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:138\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer.visit_If\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_If\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m    137\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_visit_non_loop_body(node\u001b[39m.\u001b[39mbody)\n\u001b[1;32m--> 138\u001b[0m   node\u001b[39m.\u001b[39morelse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visit_non_loop_body(node\u001b[39m.\u001b[39;49morelse)\n\u001b[0;32m    139\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:117\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer._visit_non_loop_body\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_visit_non_loop_body\u001b[39m(\u001b[39mself\u001b[39m, nodes):\n\u001b[0;32m    116\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39menter()\n\u001b[1;32m--> 117\u001b[0m   nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(nodes, after_visit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_postprocess_statement)\n\u001b[0;32m    118\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39mexit()\n\u001b[0;32m    119\u001b[0m   \u001b[39mreturn\u001b[39;00m nodes\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[1;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[0;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m   before_visit()\n\u001b[1;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[0;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:138\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer.visit_If\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_If\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m    137\u001b[0m   node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_visit_non_loop_body(node\u001b[39m.\u001b[39mbody)\n\u001b[1;32m--> 138\u001b[0m   node\u001b[39m.\u001b[39morelse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visit_non_loop_body(node\u001b[39m.\u001b[39;49morelse)\n\u001b[0;32m    139\u001b[0m   \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:117\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer._visit_non_loop_body\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_visit_non_loop_body\u001b[39m(\u001b[39mself\u001b[39m, nodes):\n\u001b[0;32m    116\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39menter()\n\u001b[1;32m--> 117\u001b[0m   nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(nodes, after_visit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_postprocess_statement)\n\u001b[0;32m    118\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Block]\u001b[39m.\u001b[39mexit()\n\u001b[0;32m    119\u001b[0m   \u001b[39mreturn\u001b[39;00m nodes\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[1;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[0;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m   before_visit()\n\u001b[1;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[0;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:131\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer.visit_For\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    129\u001b[0m node\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit(node\u001b[39m.\u001b[39mtarget)\n\u001b[0;32m    130\u001b[0m node\u001b[39m.\u001b[39miter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit(node\u001b[39m.\u001b[39miter)\n\u001b[1;32m--> 131\u001b[0m node\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visit_loop_body(node, node\u001b[39m.\u001b[39;49mbody)\n\u001b[0;32m    132\u001b[0m \u001b[39m# A continue in the else clause applies to the containing scope.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m node\u001b[39m.\u001b[39morelse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_visit_non_loop_body(node\u001b[39m.\u001b[39morelse)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\continue_statements.py:102\u001b[0m, in \u001b[0;36mContinueCanonicalizationTransformer._visit_loop_body\u001b[1;34m(self, node, nodes)\u001b[0m\n\u001b[0;32m     99\u001b[0m continue_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx\u001b[39m.\u001b[39mnamer\u001b[39m.\u001b[39mnew_symbol(\u001b[39m'\u001b[39m\u001b[39mcontinue_\u001b[39m\u001b[39m'\u001b[39m, scope\u001b[39m.\u001b[39mreferenced)\n\u001b[0;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Continue]\u001b[39m.\u001b[39mcontrol_var_name \u001b[39m=\u001b[39m continue_var\n\u001b[1;32m--> 102\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_block(nodes, after_visit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_postprocess_statement)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[_Continue]\u001b[39m.\u001b[39mused:\n\u001b[0;32m    105\u001b[0m   template \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[39m    var_name = False\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:336\u001b[0m, in \u001b[0;36mNodeStateTracker.visit_block\u001b[1;34m(self, nodes, before_visit, after_visit)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mif\u001b[39;00m before_visit:\n\u001b[0;32m    333\u001b[0m   \u001b[39m# TODO(mdan): We can modify node here too, if ever needed.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m   before_visit()\n\u001b[1;32m--> 336\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m after_visit \u001b[39mand\u001b[39;00m replacement:\n\u001b[0;32m    339\u001b[0m   replacement, new_destination \u001b[39m=\u001b[39m after_visit(replacement)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:495\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    493\u001b[0m     old_value[:] \u001b[39m=\u001b[39m new_values\n\u001b[0;32m    494\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(old_value, AST):\n\u001b[1;32m--> 495\u001b[0m     new_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(old_value)\n\u001b[0;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m new_node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m         \u001b[39mdelattr\u001b[39m(node, field)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:495\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    493\u001b[0m     old_value[:] \u001b[39m=\u001b[39m new_values\n\u001b[0;32m    494\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(old_value, AST):\n\u001b[1;32m--> 495\u001b[0m     new_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(old_value)\n\u001b[0;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m new_node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m         \u001b[39mdelattr\u001b[39m(node, field)\n",
      "    \u001b[1;31m[... skipping similar frames: Base.visit at line 314 (3 times), Base.visit at line 441 (3 times), NodeVisitor.visit at line 410 (3 times), NodeTransformer.generic_visit at line 495 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:495\u001b[0m, in \u001b[0;36mNodeTransformer.generic_visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    493\u001b[0m     old_value[:] \u001b[39m=\u001b[39m new_values\n\u001b[0;32m    494\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(old_value, AST):\n\u001b[1;32m--> 495\u001b[0m     new_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(old_value)\n\u001b[0;32m    496\u001b[0m     \u001b[39mif\u001b[39;00m new_node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m         \u001b[39mdelattr\u001b[39m(node, field)\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\converter.py:314\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    315\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ast_depth \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32me:\\work\\ENV\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m processing_expr_node:\n\u001b[0;32m    439\u001b[0m   entry_expr_value \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mvalue\n\u001b[1;32m--> 441\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Base, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mvisit(node)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m (processing_expr_node \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(result, gast\u001b[39m.\u001b[39mExpr) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     (result\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m entry_expr_value)):\n\u001b[0;32m    447\u001b[0m   \u001b[39m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[0;32m    448\u001b[0m   \u001b[39m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[0;32m    449\u001b[0m   \u001b[39m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ast.py:410\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    408\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m node\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    409\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(number_iterations):\n",
    "  # Collect a few episodes using collect_policy and save to the replay buffer.\n",
    "  collect_episode(train_env_tf, tf_agent.collect_policy, 2)\n",
    "\n",
    "  dataset = replay_buffer.as_dataset(sample_batch_size=1)\n",
    "\n",
    "  iterator = iter(dataset)\n",
    "\n",
    "  trajectories, _ = next(iterator)\n",
    "\n",
    "  train_loss = tf_agent.train(experience=trajectories)  \n",
    "\n",
    "  replay_buffer.clear()\n",
    "\n",
    "  step = tf_agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env_tf, tf_agent.policy, number_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = range(0, number_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "def compute_animation_frames(environment, policy, size_episodes=1):\n",
    "    frame = []\n",
    "    for _ in range(size_episodes):\n",
    "        time_step = environment.reset()\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            img = environment.render()\n",
    "            frame.append(img)\n",
    "    return frame\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilts import plot_animation\n",
    "frames = compute_animation_frames(eval_env_py,tf_agent.policy)\n",
    "plot_animation(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e010a72b03347896d5a708620cb2a6934ef5db96cb99d8f5b4211fde9732cbc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
