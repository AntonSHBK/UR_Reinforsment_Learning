{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=18)\n",
    "mpl.rc('xtick', labelsize=18)\n",
    "mpl.rc('ytick', labelsize=18)\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import collections\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "# from tf_env.UR_ENV import UR_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_env():\n",
    "    def __init__(self, step_size=13,targets=[166,-88],max_steps=100):\n",
    "        self.pos=np.random.uniform(-10,10,len(targets))\n",
    "        self.max_steps=max_steps\n",
    "        self.step_size=step_size\n",
    "        self.targets=targets\n",
    "        self.max_num=1000\n",
    "        self.min_num=-1000\n",
    "        self.done=False\n",
    "        self.def_size_pos=[abs(targets[i]-self.pos[i]) for i in range(len(targets))]\n",
    "        self.size_pos=[abs(targets[i]-self.pos[i]) for i in range(len(targets))]\n",
    "        self.counter_stop=0\n",
    "        self.obsevation_space=len(targets)\n",
    "        self.action_space=len(targets)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.pos=np.random.uniform(-10,10,len(self.targets))\n",
    "        self.size_pos=[abs(self.targets[i]-self.pos[i]) for i in range(len(self.targets))]\n",
    "        self.counter_stop=0\n",
    "        return self.pos\n",
    "\n",
    "    def step(self,action):\n",
    "        self.counter_stop+=1\n",
    "        if self.counter_stop>=self.max_steps:\n",
    "            self.done=True\n",
    "        self.last_pos=np.copy(self.pos) \n",
    "        self.last_size_pos=np.copy(self.size_pos)\n",
    "        self.reward=np.zeros(self.pos.shape)\n",
    "        for i in range(len(action)):\n",
    "            self.pos[i]=self.pos[i]+(action[i]*self.step_size)\n",
    "            self.size_pos[i]=abs(self.targets[i]-self.pos[i])\n",
    "            difference= self.last_size_pos[i]-self.size_pos[i]\n",
    "            self.reward[i]=difference/self.def_size_pos[i]\n",
    "        return self.pos, self.reward, self.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iterations = 100 # @param {type:\"integer\"}\n",
    "max_anglular_velocity = 2\n",
    "max_steps_env = 40\n",
    "discount = 0.95 # @param {type:\"number\"}\n",
    "\n",
    "\n",
    "fc_layer_params=(300,300)\n",
    "learning_rate = 1e-5 # @param {type:\"number\"}\n",
    "\n",
    "\n",
    "\n",
    "num_states = 2\n",
    "num_actions = 2\n",
    "\n",
    "upper_bound = 1.\n",
    "lower_bound = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "eps = np.finfo(np.float32).eps.item()# заменяет числа 0< минимальным неотрицательным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "env= simple_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor():\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.03, maxval=0.03)\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(num_states,))\n",
    "    out = tf.keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    out = tf.keras.layers.Dense(256, activation=\"relu\")(out)\n",
    "    outputs = tf.keras.layers.Dense(num_actions, activation=\"tanh\", kernel_initializer=last_init)(out)\n",
    "\n",
    "    # Our upper bound is 2.0 for Pendulum.\n",
    "    outputs = outputs * upper_bound\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_critic():\n",
    "    # State as input\n",
    "    state_input = tf.keras.layers.Input(shape=(num_states))\n",
    "    state_out = tf.keras.layers.Dense(16, activation=\"relu\")(state_input)\n",
    "    state_out = tf.keras.layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "    # Action as input\n",
    "    action_input = tf.keras.layers.Input(shape=(num_actions))\n",
    "    action_out = tf.keras.layers.Dense(32, activation=\"relu\")(action_input)\n",
    "\n",
    "    # Both are passed through seperate layer before concatenating\n",
    "    concat = tf.keras.layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = tf.keras.layers.Dense(256, activation=\"relu\")(concat)\n",
    "    out = tf.keras.layers.Dense(256, activation=\"relu\")(out)\n",
    "    outputs = tf.keras.layers.Dense(1)(out)\n",
    "\n",
    "    # Outputs single value for give state-action\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'dense_237/kernel:0' shape=(2, 16) dtype=float32, numpy=\n",
      "array([[-0.28933033,  0.00535089,  0.25376105,  0.24178982,  0.08286589,\n",
      "         0.10335058,  0.0709796 ,  0.06150675, -0.52775747,  0.29275578,\n",
      "         0.06215465,  0.29550856, -0.4218104 ,  0.24684685, -0.21573907,\n",
      "        -0.50397843],\n",
      "       [ 0.04289705,  0.44817126,  0.29120362,  0.19227606,  0.07394308,\n",
      "        -0.5757586 ,  0.5055877 ,  0.485157  ,  0.31889093, -0.3155066 ,\n",
      "         0.04323548,  0.2734403 ,  0.4611231 , -0.18214616, -0.30337626,\n",
      "         0.00328052]], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_237/bias:0' shape=(16,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_238/kernel:0' shape=(16, 32) dtype=float32, numpy=\n",
      "array([[ 0.00657356, -0.20272204,  0.3518568 , -0.03195533, -0.18345672,\n",
      "         0.27296552,  0.08643442,  0.34402594,  0.341051  ,  0.09577575,\n",
      "        -0.06829113, -0.07448915, -0.13510425, -0.12627685, -0.196596  ,\n",
      "         0.13221854,  0.04546726, -0.33147737,  0.18763456,  0.2390944 ,\n",
      "         0.05695421, -0.00301948,  0.00527021,  0.30157402, -0.31962812,\n",
      "        -0.21654208,  0.34763   , -0.14209338,  0.03146371, -0.22127037,\n",
      "        -0.08935386, -0.32153502],\n",
      "       [-0.31901565,  0.17823693, -0.03639558, -0.14191543, -0.19782871,\n",
      "        -0.29718906,  0.03988346, -0.2960811 , -0.31120786,  0.24184224,\n",
      "        -0.15661372, -0.23249456, -0.28444588,  0.30128208, -0.2941828 ,\n",
      "        -0.19512726, -0.0358668 ,  0.06138384, -0.22513741, -0.35027376,\n",
      "         0.05146247,  0.23634467, -0.24327068,  0.29105356, -0.34980905,\n",
      "         0.04678872,  0.25828514,  0.00296056,  0.18416259,  0.16669443,\n",
      "         0.09599012, -0.01380816],\n",
      "       [ 0.30417463, -0.00182489,  0.1867654 , -0.24102265, -0.20694245,\n",
      "         0.2632986 , -0.29102695,  0.10669795,  0.15458831, -0.06703794,\n",
      "         0.11035073, -0.35241222,  0.22127298,  0.1508139 , -0.27797666,\n",
      "        -0.20254375, -0.1967361 ,  0.32219973, -0.07676923,  0.27389708,\n",
      "        -0.03409967,  0.01514083, -0.13417803,  0.318952  ,  0.23661044,\n",
      "        -0.23489559, -0.11976145,  0.31963125,  0.33387956,  0.02909449,\n",
      "        -0.07008946,  0.1817908 ],\n",
      "       [ 0.01529342, -0.27036005,  0.20953694, -0.27822104,  0.21979877,\n",
      "        -0.16384056,  0.3327826 ,  0.15952888, -0.06732267,  0.19524494,\n",
      "        -0.1876467 ,  0.256779  ,  0.25949904,  0.00076276, -0.18897644,\n",
      "         0.13854983, -0.29924828, -0.16420168,  0.00141141,  0.151135  ,\n",
      "        -0.28950164, -0.25347352, -0.2578551 , -0.06854999, -0.301024  ,\n",
      "        -0.04323372, -0.32499805,  0.18886551, -0.23562491, -0.01145154,\n",
      "         0.03708905,  0.25290677],\n",
      "       [ 0.10884371,  0.03348476,  0.09954149, -0.1934129 ,  0.09366521,\n",
      "        -0.24958554, -0.06995398, -0.12178913,  0.05351099, -0.30401963,\n",
      "        -0.13102224,  0.15190366, -0.05284196, -0.13733129,  0.05726004,\n",
      "         0.17774448, -0.33384198,  0.3134496 ,  0.07474339,  0.16375157,\n",
      "        -0.34077775, -0.24559584, -0.3419845 ,  0.18835106, -0.30250016,\n",
      "         0.15690967, -0.00320148,  0.03316966, -0.0133259 , -0.33958593,\n",
      "         0.30132964,  0.04366288],\n",
      "       [-0.13690485, -0.1271932 ,  0.21720842, -0.27684444,  0.03595448,\n",
      "         0.05517384,  0.11436093, -0.03356534, -0.12531969,  0.02986121,\n",
      "         0.03087449, -0.1368278 , -0.09565464, -0.3389103 ,  0.05558783,\n",
      "        -0.13333105, -0.21802557, -0.15411897, -0.05741522,  0.3286446 ,\n",
      "         0.05187503, -0.02453697, -0.06620327,  0.27066228,  0.07273164,\n",
      "        -0.06498891,  0.24215159, -0.27526653,  0.1367693 ,  0.3103468 ,\n",
      "        -0.21500371, -0.30688983],\n",
      "       [ 0.24823752, -0.02710304, -0.07214242,  0.26074037,  0.01544335,\n",
      "         0.06513247,  0.06654677,  0.2947162 ,  0.01280901,  0.2372295 ,\n",
      "         0.06817985, -0.29822445, -0.10362923,  0.25341567,  0.00157309,\n",
      "        -0.29156464,  0.02954099, -0.27831814,  0.14564332, -0.25347874,\n",
      "         0.2617475 , -0.17852958, -0.2247253 , -0.25888264,  0.03842106,\n",
      "         0.1522533 ,  0.30732158,  0.19478986,  0.21420363,  0.12535721,\n",
      "        -0.33852163, -0.03176817],\n",
      "       [ 0.02043438,  0.31484035,  0.2213265 ,  0.19416925,  0.28624377,\n",
      "         0.13360062, -0.30314457,  0.03031927, -0.25543392, -0.20524664,\n",
      "         0.1519992 , -0.0244858 ,  0.07530546, -0.24022995,  0.24108544,\n",
      "        -0.23674214,  0.30983123, -0.3518331 , -0.20179515,  0.2967026 ,\n",
      "        -0.17667647,  0.02919301, -0.24832518,  0.20401558, -0.22953165,\n",
      "        -0.13241318,  0.23052642, -0.28310466, -0.13755113, -0.26643997,\n",
      "         0.28034768,  0.11120287],\n",
      "       [ 0.02199003, -0.22861731,  0.20477721,  0.22232589,  0.03937823,\n",
      "         0.24243239, -0.02892235,  0.05157629, -0.01962745,  0.24857149,\n",
      "         0.21762899, -0.17839454,  0.18313202, -0.12020931,  0.23523638,\n",
      "        -0.03272375,  0.18594489,  0.07733929, -0.03997138,  0.3355309 ,\n",
      "         0.10786921,  0.24881527, -0.17142649,  0.05717599, -0.03007886,\n",
      "         0.3292124 , -0.07273358, -0.20080714,  0.24847355, -0.17439641,\n",
      "        -0.03455949,  0.16162243],\n",
      "       [ 0.12981719,  0.30627188, -0.1629966 , -0.23615503,  0.31883004,\n",
      "         0.01248905,  0.17754969,  0.2839525 ,  0.31476244,  0.11404693,\n",
      "         0.02707404,  0.27928618,  0.2922915 , -0.2697604 ,  0.24107912,\n",
      "         0.20493582,  0.19757572, -0.34412023, -0.10059467,  0.07082525,\n",
      "        -0.30285206, -0.3136748 ,  0.04832128,  0.08404544,  0.01181671,\n",
      "        -0.24776876, -0.05403775, -0.23857418, -0.03846809, -0.13877398,\n",
      "        -0.24976847, -0.0027113 ],\n",
      "       [-0.08968166, -0.30025247, -0.05300927,  0.22001901, -0.20425071,\n",
      "         0.02874103, -0.34348002, -0.30765697,  0.25183567, -0.32966447,\n",
      "         0.11154678,  0.33299658, -0.09320253,  0.08237839, -0.04449823,\n",
      "         0.3404921 , -0.01526019, -0.21039833, -0.03811306,  0.2337546 ,\n",
      "        -0.3482191 , -0.11043099,  0.0023132 ,  0.25133565,  0.09520441,\n",
      "        -0.0063495 , -0.1089083 ,  0.32381383, -0.07863277, -0.20444812,\n",
      "        -0.2068461 , -0.11751738],\n",
      "       [-0.18401423,  0.10133779, -0.13173226,  0.29979768,  0.23306409,\n",
      "        -0.05439675,  0.07171279,  0.2927414 ,  0.23278692,  0.1557878 ,\n",
      "         0.2376515 ,  0.2608097 ,  0.03319064,  0.16845354, -0.13435379,\n",
      "         0.34702608, -0.30883473,  0.29864094, -0.23848525,  0.15776232,\n",
      "         0.1916928 ,  0.02972287, -0.03488538,  0.31139693,  0.34722015,\n",
      "         0.11991274, -0.17744666,  0.07016498, -0.08734143,  0.03947076,\n",
      "        -0.21319655,  0.31731912],\n",
      "       [-0.06387168,  0.12224281, -0.02110857, -0.16444284,  0.11305049,\n",
      "         0.29957482,  0.0679048 , -0.02100945, -0.08250558,  0.3073425 ,\n",
      "        -0.02139002, -0.25361866,  0.22325608,  0.21591732, -0.3501722 ,\n",
      "        -0.06934962, -0.16488682, -0.09204113, -0.10105467,  0.25895604,\n",
      "        -0.0318163 , -0.0467439 , -0.00414792,  0.23847452,  0.08382654,\n",
      "         0.07492927,  0.20537165, -0.15853326,  0.32800314,  0.2945648 ,\n",
      "        -0.17967513, -0.3301108 ],\n",
      "       [-0.1196291 ,  0.02395248, -0.17643487, -0.00446865, -0.2178375 ,\n",
      "        -0.31359464, -0.2829445 , -0.14198986,  0.23324403, -0.03594771,\n",
      "        -0.1637352 ,  0.02936286, -0.09846708,  0.10319772,  0.2714338 ,\n",
      "         0.08168867,  0.14575654,  0.20877692, -0.30902   , -0.20808287,\n",
      "         0.19779661,  0.03043872,  0.21497402,  0.00214577,  0.07707816,\n",
      "         0.13103524,  0.21545222,  0.03627697, -0.11543803, -0.04032847,\n",
      "         0.1640813 ,  0.2187691 ],\n",
      "       [ 0.34609738, -0.33971372,  0.20978215,  0.17963347,  0.33196577,\n",
      "        -0.0039199 ,  0.23208675,  0.0601508 ,  0.23796007,  0.06365025,\n",
      "        -0.12999968,  0.30532393, -0.3403214 , -0.2553417 ,  0.03143167,\n",
      "         0.01164737,  0.06541535, -0.08887085, -0.32482415,  0.24386534,\n",
      "         0.31978837,  0.10991088,  0.21615264, -0.17705259,  0.09582281,\n",
      "        -0.11779572, -0.06769088, -0.13325426, -0.08335567, -0.06088838,\n",
      "        -0.1279065 ,  0.186744  ],\n",
      "       [ 0.3508955 , -0.34881836, -0.04744345,  0.30873576, -0.15119617,\n",
      "        -0.04468071,  0.02768087,  0.2174603 , -0.06988445,  0.2155272 ,\n",
      "        -0.00089714, -0.05510178, -0.24770908, -0.11802492,  0.30520675,\n",
      "        -0.1335847 , -0.12555462, -0.02720681,  0.19367722, -0.09453806,\n",
      "         0.33426157,  0.14437073, -0.14310305, -0.06161541, -0.1254989 ,\n",
      "        -0.07115957, -0.28858715,  0.20808879, -0.03634298,  0.17275175,\n",
      "        -0.11061254,  0.08513916]], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_238/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_239/kernel:0' shape=(2, 32) dtype=float32, numpy=\n",
      "array([[ 0.23029205, -0.0429258 ,  0.07017669, -0.00590199,  0.2383773 ,\n",
      "        -0.01632559,  0.40780994,  0.15977791, -0.05537134,  0.31756023,\n",
      "        -0.2659385 , -0.09385234,  0.18451521,  0.09072354,  0.17218414,\n",
      "         0.21873912, -0.38442814, -0.29581887, -0.20197926,  0.3724639 ,\n",
      "         0.33043805, -0.043571  ,  0.30009422,  0.29460922,  0.07084873,\n",
      "         0.04622123,  0.3493888 , -0.06125522,  0.22208312,  0.18980065,\n",
      "         0.1919721 ,  0.24973199],\n",
      "       [-0.37600303,  0.05651462,  0.21700993,  0.14071354,  0.27715483,\n",
      "        -0.15948346,  0.24194553,  0.3564014 ,  0.2979575 ,  0.36430833,\n",
      "        -0.3303427 , -0.12340221,  0.24033114,  0.13079503,  0.34436873,\n",
      "         0.18975857, -0.18459141,  0.07149965, -0.2852267 , -0.36553025,\n",
      "         0.16546836, -0.06505433,  0.28229353,  0.27724054,  0.16288063,\n",
      "         0.2985914 , -0.11680424,  0.04197583, -0.1070793 ,  0.14291987,\n",
      "         0.24632588,  0.29200146]], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_239/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_240/kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
      "array([[ 0.08328599, -0.08819617,  0.06456859, ..., -0.10662918,\n",
      "        -0.05955372, -0.13118614],\n",
      "       [ 0.10653333, -0.066894  , -0.01899515, ...,  0.11882582,\n",
      "         0.03800277,  0.0771673 ],\n",
      "       [ 0.08799243,  0.04914905,  0.01005831, ..., -0.0272436 ,\n",
      "        -0.037929  ,  0.0256477 ],\n",
      "       ...,\n",
      "       [ 0.1362839 ,  0.1141564 , -0.04327674, ...,  0.03299356,\n",
      "        -0.07056405, -0.12866199],\n",
      "       [-0.09476115, -0.06590075, -0.07902966, ...,  0.12687302,\n",
      "         0.00938044, -0.00343069],\n",
      "       [ 0.11441037, -0.01422735, -0.09964524, ...,  0.09548526,\n",
      "         0.10159197,  0.07354406]], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_240/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_241/kernel:0' shape=(256, 256) dtype=float32, numpy=\n",
      "array([[-0.07248243, -0.08202519,  0.08633437, ..., -0.0705711 ,\n",
      "        -0.10612765, -0.06480416],\n",
      "       [ 0.0471387 , -0.03377332,  0.03743561, ...,  0.09350755,\n",
      "        -0.02089011, -0.08054991],\n",
      "       [-0.10051198,  0.07125286,  0.09038932, ...,  0.00803103,\n",
      "        -0.02817757, -0.04053096],\n",
      "       ...,\n",
      "       [ 0.03033403,  0.07316906, -0.05450901, ...,  0.02621893,\n",
      "         0.06997696, -0.02237383],\n",
      "       [ 0.03458371, -0.05703189,  0.09259931, ..., -0.08673816,\n",
      "         0.05351929,  0.05094301],\n",
      "       [-0.07314816,  0.0534712 ,  0.05090667, ..., -0.01046348,\n",
      "        -0.01141268,  0.04754982]], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_241/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_242/kernel:0' shape=(256, 1) dtype=float32, numpy=\n",
      "array([[-0.13769588],\n",
      "       [ 0.13879855],\n",
      "       [-0.10525783],\n",
      "       [-0.12042544],\n",
      "       [ 0.06066668],\n",
      "       [ 0.0239761 ],\n",
      "       [-0.1120883 ],\n",
      "       [-0.14279346],\n",
      "       [-0.03864664],\n",
      "       [ 0.06940892],\n",
      "       [-0.14568706],\n",
      "       [ 0.05744985],\n",
      "       [ 0.01063174],\n",
      "       [-0.11224316],\n",
      "       [-0.03171658],\n",
      "       [-0.08242586],\n",
      "       [ 0.0269991 ],\n",
      "       [ 0.03622296],\n",
      "       [-0.12047808],\n",
      "       [ 0.05509189],\n",
      "       [ 0.00113   ],\n",
      "       [ 0.0545141 ],\n",
      "       [-0.01759809],\n",
      "       [ 0.14098762],\n",
      "       [ 0.03136776],\n",
      "       [ 0.03776291],\n",
      "       [-0.02508792],\n",
      "       [-0.07018843],\n",
      "       [ 0.04377371],\n",
      "       [ 0.12339626],\n",
      "       [ 0.07156515],\n",
      "       [ 0.02671838],\n",
      "       [ 0.10057347],\n",
      "       [ 0.12133493],\n",
      "       [-0.1033719 ],\n",
      "       [-0.00816312],\n",
      "       [-0.07818189],\n",
      "       [-0.01430584],\n",
      "       [-0.0765891 ],\n",
      "       [ 0.00125079],\n",
      "       [-0.07915721],\n",
      "       [ 0.03668311],\n",
      "       [-0.03311691],\n",
      "       [-0.13107051],\n",
      "       [ 0.1447386 ],\n",
      "       [-0.11408608],\n",
      "       [-0.10340938],\n",
      "       [-0.10986994],\n",
      "       [ 0.07794562],\n",
      "       [ 0.09364545],\n",
      "       [-0.04878958],\n",
      "       [ 0.03163338],\n",
      "       [ 0.01312652],\n",
      "       [-0.02403276],\n",
      "       [-0.04308852],\n",
      "       [-0.13280903],\n",
      "       [-0.05939414],\n",
      "       [ 0.05351986],\n",
      "       [ 0.12638451],\n",
      "       [-0.04271112],\n",
      "       [ 0.01165044],\n",
      "       [ 0.06827612],\n",
      "       [ 0.01625709],\n",
      "       [ 0.12358592],\n",
      "       [-0.14458953],\n",
      "       [ 0.01566093],\n",
      "       [-0.13538595],\n",
      "       [-0.02353685],\n",
      "       [-0.11574546],\n",
      "       [ 0.11756332],\n",
      "       [ 0.01107344],\n",
      "       [-0.04730221],\n",
      "       [-0.11419642],\n",
      "       [ 0.12890635],\n",
      "       [ 0.12307571],\n",
      "       [ 0.03091893],\n",
      "       [-0.14131683],\n",
      "       [ 0.04301256],\n",
      "       [-0.09003146],\n",
      "       [ 0.08423409],\n",
      "       [-0.14986038],\n",
      "       [ 0.06849043],\n",
      "       [-0.01449206],\n",
      "       [-0.09136801],\n",
      "       [-0.08083325],\n",
      "       [-0.1063295 ],\n",
      "       [ 0.07953233],\n",
      "       [ 0.04972315],\n",
      "       [-0.08573424],\n",
      "       [ 0.03988217],\n",
      "       [-0.12224548],\n",
      "       [-0.07423556],\n",
      "       [-0.09163831],\n",
      "       [-0.11492657],\n",
      "       [ 0.00280249],\n",
      "       [-0.09101523],\n",
      "       [ 0.03573158],\n",
      "       [-0.12431291],\n",
      "       [ 0.09960975],\n",
      "       [ 0.07993345],\n",
      "       [-0.12589076],\n",
      "       [ 0.03896841],\n",
      "       [-0.02900358],\n",
      "       [ 0.12205885],\n",
      "       [ 0.05134694],\n",
      "       [ 0.11270969],\n",
      "       [ 0.07323915],\n",
      "       [-0.03752068],\n",
      "       [ 0.03150328],\n",
      "       [-0.04847089],\n",
      "       [-0.04311092],\n",
      "       [ 0.13055478],\n",
      "       [-0.11331359],\n",
      "       [ 0.11467664],\n",
      "       [ 0.02389291],\n",
      "       [ 0.09393933],\n",
      "       [-0.05249016],\n",
      "       [ 0.01176885],\n",
      "       [ 0.08054742],\n",
      "       [-0.09048828],\n",
      "       [ 0.12420715],\n",
      "       [-0.10799235],\n",
      "       [ 0.05942048],\n",
      "       [ 0.07852452],\n",
      "       [ 0.06423062],\n",
      "       [ 0.01444933],\n",
      "       [ 0.1475242 ],\n",
      "       [ 0.11840864],\n",
      "       [-0.11845896],\n",
      "       [ 0.10540949],\n",
      "       [-0.03357282],\n",
      "       [-0.14927216],\n",
      "       [ 0.03652158],\n",
      "       [-0.07660269],\n",
      "       [-0.09090073],\n",
      "       [-0.06194703],\n",
      "       [-0.06014134],\n",
      "       [ 0.00100425],\n",
      "       [-0.10183629],\n",
      "       [-0.01488331],\n",
      "       [-0.05224623],\n",
      "       [ 0.04508823],\n",
      "       [ 0.12406968],\n",
      "       [ 0.04227979],\n",
      "       [ 0.06010629],\n",
      "       [-0.0553736 ],\n",
      "       [ 0.00641379],\n",
      "       [ 0.07389086],\n",
      "       [-0.05565304],\n",
      "       [ 0.12104838],\n",
      "       [ 0.06220058],\n",
      "       [-0.00708169],\n",
      "       [-0.01602548],\n",
      "       [-0.0524961 ],\n",
      "       [-0.10584147],\n",
      "       [-0.08118325],\n",
      "       [-0.07819741],\n",
      "       [ 0.14111812],\n",
      "       [-0.14324838],\n",
      "       [ 0.09168185],\n",
      "       [-0.04183918],\n",
      "       [-0.07110291],\n",
      "       [ 0.01810172],\n",
      "       [-0.05645048],\n",
      "       [ 0.09828176],\n",
      "       [-0.07073796],\n",
      "       [ 0.13150518],\n",
      "       [-0.03914536],\n",
      "       [ 0.00341214],\n",
      "       [ 0.05687393],\n",
      "       [-0.07096072],\n",
      "       [-0.04955954],\n",
      "       [ 0.13084008],\n",
      "       [ 0.01384814],\n",
      "       [ 0.12534533],\n",
      "       [-0.14505899],\n",
      "       [ 0.06567733],\n",
      "       [-0.12411448],\n",
      "       [ 0.06074359],\n",
      "       [-0.03093357],\n",
      "       [ 0.11500897],\n",
      "       [ 0.07335751],\n",
      "       [-0.09521002],\n",
      "       [ 0.14303924],\n",
      "       [ 0.0793301 ],\n",
      "       [ 0.12583397],\n",
      "       [-0.02205352],\n",
      "       [ 0.1452957 ],\n",
      "       [ 0.09532098],\n",
      "       [ 0.12694012],\n",
      "       [-0.14277062],\n",
      "       [ 0.09837164],\n",
      "       [ 0.11046849],\n",
      "       [ 0.08900683],\n",
      "       [ 0.06333396],\n",
      "       [-0.03787347],\n",
      "       [ 0.01405488],\n",
      "       [ 0.13454776],\n",
      "       [-0.05376631],\n",
      "       [-0.1280701 ],\n",
      "       [-0.02825355],\n",
      "       [ 0.12564702],\n",
      "       [-0.0536788 ],\n",
      "       [-0.09071691],\n",
      "       [ 0.0791932 ],\n",
      "       [-0.01699822],\n",
      "       [-0.10733069],\n",
      "       [-0.12518418],\n",
      "       [ 0.1150638 ],\n",
      "       [-0.11161403],\n",
      "       [ 0.09667619],\n",
      "       [ 0.03899865],\n",
      "       [-0.09341978],\n",
      "       [-0.0326445 ],\n",
      "       [-0.03630996],\n",
      "       [ 0.01020974],\n",
      "       [ 0.01331748],\n",
      "       [ 0.12953912],\n",
      "       [ 0.08235814],\n",
      "       [-0.05934616],\n",
      "       [-0.15250827],\n",
      "       [-0.11372244],\n",
      "       [-0.00530703],\n",
      "       [-0.0141854 ],\n",
      "       [-0.13716985],\n",
      "       [-0.13453883],\n",
      "       [ 0.05789071],\n",
      "       [-0.1282862 ],\n",
      "       [ 0.02348074],\n",
      "       [-0.0454594 ],\n",
      "       [-0.05964557],\n",
      "       [-0.14288832],\n",
      "       [ 0.10982405],\n",
      "       [-0.1434621 ],\n",
      "       [ 0.08634119],\n",
      "       [-0.1051001 ],\n",
      "       [-0.01743019],\n",
      "       [-0.09948257],\n",
      "       [-0.08052589],\n",
      "       [-0.14514248],\n",
      "       [ 0.12474306],\n",
      "       [ 0.013457  ],\n",
      "       [-0.09032464],\n",
      "       [ 0.00945418],\n",
      "       [ 0.06989393],\n",
      "       [ 0.13837634],\n",
      "       [ 0.0668216 ],\n",
      "       [-0.01996045],\n",
      "       [ 0.11872791],\n",
      "       [-0.12412329],\n",
      "       [-0.10331868],\n",
      "       [ 0.0854822 ],\n",
      "       [ 0.07158461],\n",
      "       [ 0.01978755],\n",
      "       [-0.04698706],\n",
      "       [-0.08240619]], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'dense_242/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "\n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "# for var in critic_model.trainable_variables:\n",
    "#   print(var, \"\\n\")\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "\n",
    "# Making the weights equal initially\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_lr = 0.5\n",
    "actor_lr = 0.2\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 50\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "# Used to update target networks\n",
    "tau = 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "    return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_counter = 0\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        self.buffer_counter += 1\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + gamma * target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch, training=True)\n",
    "            critic_value = critic_model([state_batch, actions], training=True)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "    def learn(self):\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "\n",
    "\n",
    "# This update target parameters slowly\n",
    "# Based on rate `tau`, which is much less than one.\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n",
      "WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.\n"
     ]
    }
   ],
   "source": [
    "buffer = Buffer(50000, 1)\n",
    "ep_reward_list = []\n",
    "avg_reward_list = []\n",
    "for ep in range(total_episodes):\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "    while True:\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "        action = policy(tf_prev_state, ou_noise)\n",
    "        state, reward, done = env.step(action[0])\n",
    "        buffer.record((prev_state, action[0], np.mean(reward), state))\n",
    "        episodic_reward += reward\n",
    "        buffer.learn()\n",
    "        update_target(target_actor.variables, actor_model.variables, tau)\n",
    "        update_target(target_critic.variables, critic_model.variables, tau)\n",
    "        if done:\n",
    "            break\n",
    "        prev_state = state\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "    avg_reward = np.mean(ep_reward_list[-2:])\n",
    "    print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "    avg_reward_list.append(avg_reward)\n",
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "def compute_animation_frames(environment):\n",
    "    frame = []\n",
    "    for _ in range(1):\n",
    "        time_step = env.reset()\n",
    "        while True:\n",
    "            action = policy(tf_prev_state, ou_noise)\n",
    "            state, reward, done, info = env.step(action[0])\n",
    "            img = environment.render()\n",
    "            frame.append(img)\n",
    "            if done: break\n",
    "    return frame\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=100):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [173], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m frames \u001b[39m=\u001b[39m compute_animation_frames(env)\n",
      "Cell \u001b[1;32mIn [172], line 8\u001b[0m, in \u001b[0;36mcompute_animation_frames\u001b[1;34m(environment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     action \u001b[39m=\u001b[39m policy(tf_prev_state, ou_noise)\n\u001b[1;32m----> 8\u001b[0m     state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action[\u001b[39m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m     img \u001b[39m=\u001b[39m environment\u001b[39m.\u001b[39mrender()\n\u001b[0;32m     10\u001b[0m     frame\u001b[39m.\u001b[39mappend(img)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "frames = compute_animation_frames(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_animation(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e010a72b03347896d5a708620cb2a6934ef5db96cb99d8f5b4211fde9732cbc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
